# Literate Programming

## The approach

The main idea of the extension is to collect all fragments that are created in
all `.literate` files.

Once all fragments have been collected they are expanded such that eventually
there will be only the top fragments. A top fragment specifies a file to which
it will be written.

The first step is to put each `.literate` file through the *MarkdownIt* renderer.
Each rendering will be given a special environment that will be used to collect
the state for the render. The state will contain all the tokens as recognized by
the renderer. The state `env` is of type `GrabbedState`, and used to collect the
tokens generated by *MarkdownIt* parser. The tokens are needed to find all the
fragments for our programs. For each `.literate` file the grabbed state `env` is
saved in the list of `GrabbedState`s `envList`.

Each rendered file will be saved as a `HTML` file with the same name
as the `.literate` file that was being rendered, but with the extension replaced
with `.html`.

```ts : <<render and collect state>>=
/** All .literate files found in our workspace */
const foundLiterateFiles = await vscode.workspace
	.findFiles('**/*.literate')
	.then(files => Promise.all(files.map(file => file)));

// handle all .literate file, extract code and write out.
try {
	for (let fl of foundLiterateFiles) {
		const uri = vscode.Uri.file(fl.path);
		const content = await vscode.workspace.fs.readFile(uri);
		let fname = fl.path.replace(folderUri.path, '');
		/** Environment where we can grab the state. */
		const env: GrabbedState = { literateFileName: fname, literateUri: uri, gstate: new StateCore('', md, {}) };
		const text = new TextDecoder('utf-8').decode(content);
		envList.push(env);
		const rendered = md.render(text, env);
		const html =
`<html>
	<head>
		<link rel="stylesheet" type="text/css" href="./style.css">
	</head>
	<body>
	${rendered}
	</body>
</html>`;
		const encoded = Buffer.from(html, 'utf-8');
		fname = fname.replace(".literate", ".html");
		const fileUri = folderUri.with({ path: posix.join(sourceUri.path, fname) });
		await vscode.workspace.fs.writeFile(fileUri, encoded);
	}
} catch (error) {
	console.log(error);
}
```

### GrabbedState interface

The `GrabbedState` interface is used to create a type that helps us collecting
the tokens for each `.literate` file. Instances of objects with this interface
are passed to a *MarkdownIt* renderer. The renderer will have the
`GrabberPlugin` registered. This provides a rule that helps us collecting the
states of each rendered file. The grabbed state is collected in `gstate`, which
is an instance of the `StateCore`, provided by *MarkdownIt*.

```ts : <<grabbed state type>>=
/**
 * Interface for environment to hold the Markdown file name and the StateCore
 * grabbed by the grabberPlugin.
 * The gstate we use to access all the tokens generated by the MarkdownIt parser.
 *
 * @see StateCore
 */
interface GrabbedState {
	/**
	 * File name of the Markdown document to which the state belongs.
	 */
	literateFileName: string;
	/**
	 * Uri for the Markdown document.
	 */
	literateUri: vscode.Uri;
	/**
	 * State grabbed from the MarkdownIt parser.
	 */
	gstate: StateCore;
}
```

## Preparing MarkdownIt

We set up the *MarkdownIt* for our purposes. The highlight function we use to
ensure our code fragments get syntax highlighting. This simply relies on
*highlight.js* to do the work.

We also tell *MarkdownIt* to use our `grabberPlugin`. This plug-in harvests the
internal states for each document into instances of `GrabbedState`. These states
we'll later use to get all the different code fragments and to weave them into
the code files they describe.

Finally we replace the default `fence` rule with our own `renderCodeFence` rule.
The intent of that rule will be explained in the section on `renderCodeFence`.

```ts : <<set up MarkdownIt>>=
/**
	* MarkdownIt instance with grabber_plugin in use.
	*/
const md : MarkdownIt = new MarkdownIt({
		highlight: function(str: string, lang: string, attrs: string) {
			if(lang && hljs.getLanguage(lang)) {
				return '<pre><code>' +
				hljs.highlight(str, {language : lang}).value +
				'</code></pre>';
			}
			return '<pre title="' + attrs + '">' + md.utils.escapeHtml(str) + '</pre>';
		}

	})
	.use(grabberPlugin);

oldFence = md.renderer.rules.fence;
md.renderer.rules.fence = renderCodeFence;
```

## Fragment structure and regular expressions

Before we dive deeper into the processing of `.literate` documents it is
necessary to have a look at how fragments work.

Fragments in the `literate` extension have a specific format that requires a bit
of explaining.

There are four types of fragment tags, three of which either create or modify a
fragment, and one that expresses fragment usage.

For the detection of fragments a couple of regular expressions are used. These
are explained in more detail below.

### Fragment use in code

Lets start by looking at the form for fragment tag use.

Fragments can be used in code blocks by using their tag double opening and
closing chevrons around the fragment name `<<fragment name>>`. To detect usage
of fragments in code we use `FRAGMENT_USE_IN_CODE_RE`.

The regular expression captures four groups. A match will give us 5 or more
results, the whole string matched and the groups. There may be some additional
parts after that, but those we will discard. The whole string matched is called
the `tag`. The first group is called `indent`, which will be used to indent the
whole fragment code when it gets extrapolated into the final code. The second
group is called `tagName`, which is the fragment name. The third group is called
`root` and the final group is called `add`. For fragment use we essentially need
only the second group `tagName`, with the `indent` still serving a function. The
other groups are in the regular expression so we can identify incorrect use of
fragments in code: creating or adding to fragments inside code blocks is not
valid.

The application of `FRAGMENT_USE_IN_CODE_RE` is explained in more detail in the
section on code realization.

``` ts : <<fragment regular expressions>>=
//let HTML_ENCODED_FRAGMENT_TAG_RE = /(&lt;&lt.*?&gt;&gt;)/g;
let FRAGMENT_USE_IN_CODE_RE = /([ \t]*)<<(.*)>>(=)?(\+)?/g;
```

### Creating and modifying fragments

There is the tag used to create a new fragment, which is always in conjunction
with the opening code fence tag. This means either a triple backtick or triple
tilde followed by the programming language identifier for the following code
block. The actual fragment tag is placed as first option right after the color
following the language specifier.

``` ts : <<fragment regular expressions>>=+
let FRAGMENT_RE = /(.*):.*<<(.*)>>(=)?(\+)?\s*(.*)/;
```

Most of the groups correspond to the ones defined by `FRAGMENT_USE_IN_CODE_RE`
with a few additions. Most notably there is the group catching the language
specifier, and the group to catch the filename, called `lang` and `fileName`
respectively.

So to create a new tag the info line for the code fence could look like
`py : <<a fragment name>>=`.

To add to a fragment a `+` is added, so it could look like
`py : <<a fragment name>>=+`. Having a fragment without `=` or `=+` on the code
fence info line is an error.

## Gathering all fragments

All code fragments are fetched from each environment state. This is done through
looking for all `fence` tokens. If the `token.info` for a `fence` matches the
`FRAGMENT_RE` we can check to see whether the fragment we have currently in our
hands is a new fragment (`root && !add`) or whether this one expands an existing
one (`root && add`), as will be explained in more detail further down.

### Populating the fragment map

First we build a map of all available fragments. These will go into `fragments`,
which is of type `Map<string, FragmentInformation>`. The name of a fragment will
function as the key, and an instance of `FragmentInformation` will be the value.

```ts : <<build fragment map>>=
/**
 * Map of fragment names and tuples of code fragments for these. The
 * tuples contain code language identifier followed by the filename and
 * lastly followed by the actual code fragment.
 */
const fragments = new Map<string, FragmentInformation>();
// Now we have the state, we have access to the tokens
// over which we can iterate to extract all the code
// fragments and build up the map with the fragments concatenated
// where necessary. We'll extrapolate all fragments in the second
// pass.
for (let env of envList) {
    for (let token of env.gstate.tokens) {
        <<handle fence tokens>>
    }
}
```

Each `fence` token we find we need to check. There may be of course code fences
in the document that do not create or modify a fragment. These we need to skip.

Since we are handling code fences we use `FRAGMENT_RE` to match `token.info`.

```ts : <<handle fence tokens>>=
if (token.type === 'fence') {
	const linenumber = locationOfFragment(token);
	const match = token.info.match(FRAGMENT_RE);
	if (match) {
		let [_, lang, name, root, add, fileName, ...__] = match;
		lang = lang.trim();
		<<add to existing fragment>>
		<<create a new fragment>>
	}
}
```

### Creating a new fragment

If the `root` group has captured a result, but the `add` group not we know we
have a new fragment on our hand.

If we already have in our `fragments` map a key with the same `name` as the
fragment we are currently handling we add an error diagnostic message. We don't
stop handling fences, or the entire `literate.process` command for that matter.
We keep on going, but leave it up to the programmer to see and handle the error
messages.

If a fragment name with `.*` is found we need to ensure there is a result in the
`fileName` capture group. That is going to be needed to write out the source
code file eventually. A file defining fragment without a file name is an error.

When everything appears to be in order a new `FragmentInformation` instance is
created with the information found. The code for this fragment is the token
content in `token.content`. Finally the new `FragmentInformation` instance is
added to the `fragments` map.

``` ts : <<create a new fragment>>=
if (root && !add) {
	if (fragments.has(name)) {
		let msg = `Trying to overwrite existing fragment fragment ${name}. ${env.literateFileName}${linenumber}`;
		const diag = createErrorDiagnostic(token, msg);
		updateDiagnostics(env.literateUri, diagnostics, diag);
	} else {
		if (!fileName && name.indexOf(".*") > -1) {
			let msg = `Expected filename for star fragment ${name}`;
			const diag = createErrorDiagnostic(token, msg);
			updateDiagnostics(env.literateUri, diagnostics, diag);
		} else {
			let code = token.content;
			let fragmentInfo: FragmentInformation = {
				lang: lang,
				literateFileName: env.literateFileName,
				sourceFileName: fileName,
				code: code,
				tokens: [token],
				env: env,
			};
			fragments.set(name, fragmentInfo);
		}
	}
}
```

### Modifying an exiting fragment

If both the `root` and `add` groups have capture their results, an `=` and an
`+` respectively we need to add code to an existing fragment.

For this to work a new fragment needs to be always present before the modifying
fragment. It is an error to try to modify a fragment that hasn't been seen yet.

The fragment with specified `name` is fetched, and when it is not `undefined`
the `token.content` is appended to the `code` of the `FragmentInformation`
instance we got from the map. The current token is also appended to the `tokens`
list.

The fragments map is updated with the modified  `FragmentInformation` instance.

``` ts : <<add to existing fragment>>=
if (root && add) {
	if (fragments.has(name)) {
		let fragmentInfo = fragments.get(name) || undefined;
		if(fragmentInfo && fragmentInfo.code) {
			let additionalCode = token.content;
			fragmentInfo.code = `${fragmentInfo.code}${additionalCode}`;
			fragmentInfo.tokens.push(token);
			fragments.set(name, fragmentInfo);
		}
	} else {
		let msg = `Trying to add to non-existant fragment ${name}. ${env.literateFileName}:${linenumber}`;
		const diag = createErrorDiagnostic(token, msg);
		updateDiagnostics(env.literateUri, diagnostics, diag);
	}
}
```

### The FragmentInformation type

We have now seen the `FragmentInformation` type being used several times, so it
is important to take a moment to clarify it in more detail.

The interface allows us to gather information for each found code fragment. It
allows us to store the programming language identifier, name of the `.literate`
file and name of the targeted source file, if the code fragment happens to be a
top fragment.

The actual code for the fragment is stored in `code`. Furthermore the tokens for
the complete fragment are stored in the `tokens` list. This list is of objects
that fullfill the `Token` interface, which is provided by the *MarkdownIt*
module.

``` ts : <<fragment information type>>=
/**
 * Interface denoting a fragment and related information
 */
interface FragmentInformation {
	/**
	 * Programming language identifier for fragment.
	 */
	lang: string;
	/**
	 * Filename of literate file.
	 */
	literateFileName: string;
	/**
	 * Filename of target source file. This is set when the fragment
	 * is a top fragment.
	 */
	sourceFileName: string;
	/**
	 * The code fragment.
	 */
	code: string;
	/**
	 * List of tokens that make up the entire code fragment.
	 */
	tokens: Token[];
	/**
	 * The GrabbedState related to this fragment.
	 */
	env: GrabbedState;
}
```

## Extrapolating fragments

Once all fragments have been collected from the `.literate` files of the project
fragments can be combined into source code.

``` ts : <<extrapolate fragments>>=
// for now do several passes
let pass: number = 0;
do {
	pass++;
	let fragmentReplaced = false;
	for (let fragmentName of fragments.keys()) {
		let fragmentInfo = fragments.get(fragmentName) || undefined;
		if (!fragmentInfo) {
			continue;
		}

		const casesToReplace = [...fragmentInfo.code.matchAll(FRAGMENT_USE_IN_CODE_RE)];
		for (let match of casesToReplace) {
			let [tag, indent, tagName, root, add, ...rest] = match;
			if (root) {
				let msg = `Found '=': incorrect fragment tag in fragment, ${tag}`;
				const diag = createErrorDiagnostic(fragmentInfo.tokens[0], msg);
				updateDiagnostics(fragmentInfo.env.literateUri, diagnostics, diag);
			}
			if (add) {
				let msg = `Found '+': incorrect fragment tag in fragment: ${tag}`;
				const diag = createErrorDiagnostic(fragmentInfo.tokens[0], msg);
				updateDiagnostics(fragmentInfo.env.literateUri, diagnostics, diag);
			}
			if (!fragments.has(tagName) && tagName !== "(.*)") {
				let msg = `Could not find fragment ${tag} (${tagName})`;
				const diag = createErrorDiagnostic(fragmentInfo.tokens[0], msg);
				updateDiagnostics(fragmentInfo.env.literateUri, diagnostics, diag);
			}
			let fragmentToReplaceWith = fragments.get(tagName) || undefined;
			if (fragmentToReplaceWith) {
				let code = fragmentToReplaceWith.code;
				let lines = code.split("\n").slice(0, -1);
				let indentedLines = lines.flatMap(function (e, _) {
					return indent + e;

				});
				let newcode = indentedLines.join("\n");
				fragmentReplaced = true;
				fragmentInfo.code = fragmentInfo.code.replace(tag, newcode);
				fragments.set(fragmentName, fragmentInfo);
			}
		}
	}
	if(!fragmentReplaced) {
		break;
	}
}
while (pass < 25);
```

## custom code fence rendering

Our extension uses a custom code fence rendering rule to ensure the code
fragment name is also rendered as part of the fence.

Essentially the old, default rendering rule for fences is first used to create
the original fence.

Then the `token.info` is matched against the `FRAGMENT_RE` regular expression.
If we have a match we prepare the `HTML` code to essentially wrap around the
`HTML` as generated by the default rule.

```ts : <<renderCodeFence rule>>=
function renderCodeFence(tokens : Token[], idx : number, options : MarkdownIt.Options, env : any, slf : Renderer) {
	let rendered = '';
	if (oldFence) {
		rendered = oldFence(tokens, idx, options, env, slf);

		let token = tokens[idx];
		if (token.info) {
			const match = token.info.match(FRAGMENT_RE);
			if (match) {
				// eslint-disable-next-line @typescript-eslint/naming-convention
				let [_, lang, name, root, add, __, ...___] = match;
				lang = lang.trim();
				if (name) {
					root = root || '';
					add = add || '';
					rendered = `<div class="codefragment"><div class="fragmentname">&lt;&lt;${name}&gt;&gt;${root}${add}</div><div class="code">${rendered}</div></div>`;
					//rendered = rendered.replaceAll(HTML_ENCODED_FRAGMENT_TAG_RE, codeFragmentCleanup);
				}
			}
		}
	}

	return rendered;
};
```

## Register the literate.process command

The command `literate.process` is registered with Visual Studio Code. The
disposable that gets returned by `registerCommand` is held in
`literateProcessDisposable` so that it can be used later on, for instance for
diagnostics management.

Here we find the main program of our `literate.process` command. Our
*MarkdownIt* is set up, `.literate` files are searched and iterated. Each
`.literate` file is rendered, and code fragments are harvested. Finally code
fragments are extrapolated and saved to their respective source code files. The
`HTML` files are also saved to files.

Diagnostic messages are also handled here. Errors and warnings are shown where
necessary. On successfull completion a simple status bar message will be used.
An information diagnostic message is not good here, because that will prevent
the usage of `literate.process` in for instance `tasks.json`, since the
diagnostic message will block execution of a task if it were used as prelaunch
task. That is obviously not good for the workflow.

```ts : <<register literate.process>>=
	// The command has been defined in the package.json file
	// Now provide the implementation of the command with registerCommand
	// The commandId parameter must match the command field in package.json
	let literateProcessDisposable = vscode.commands.registerCommand('literate.process', async function () {

		<<set up MarkdownIt>>

		diagnostics.clear();

		if (!vscode.workspace.workspaceFolders) {
			return vscode.window.showInformationMessage("No workspace or folder opened");
		}

		/**
		 * Contains environments for each Markup document parsed and rendered.
		 */
		const envList: Array<GrabbedState> = new Array<GrabbedState>();
		/**
		 * The URI for the workspace folder that will be searched for .literate
		 * files to generate code and documentation for.
		 */
		const folderUri = vscode.workspace.workspaceFolders[0].uri;
		/** The Uri for the parent path where generated code is saved. */
		const sourceUri = folderUri;

		// ensure the path exists.
		vscode.workspace.fs.createDirectory(sourceUri);

		<<render and collect state>>

		<<build fragment map>>

		<<extrapolate fragments>>

		/* now write out the source files. */
		for(const name of fragments.keys()) {
			if (name.indexOf(".*") >= 0) {
				let fragmentInfo = fragments.get(name) || undefined;
				if (fragmentInfo) {
					let fileName = fragmentInfo.sourceFileName.trim();
					const encoded = Buffer.from(fragmentInfo.code, 'utf-8');
					const fileUri = folderUri.with({ path: posix.join(sourceUri.path, fileName) });
					await vscode.workspace.fs.writeFile(fileUri, encoded);
				}
			}
		}

		let hasAnyDiagnostics = false;
		diagnostics.forEach(function(_: vscode.Uri, diags: readonly vscode.Diagnostic[], __: vscode.DiagnosticCollection) : any {
			hasAnyDiagnostics ||= (diags.length > 0);
		}
		);

		if (hasAnyDiagnostics) {
			return vscode.window.showErrorMessage("Error encountered during process");
		}
		else {
			return vscode.window.setStatusBarMessage("Literate Process completed", 5000);
		}
	});
```

## The extension file

Our Visual Studio Code entry file is the `extension.ts` file. While developing
the plug-in the JavaScript version created from this, in `out/extension.js` is
set as the entry point for the extension, in `package.json`. But when it is
prepared for release on the Visual Studio Code marketplace this needs to be
changed to the minified and bundled version that gets realized as `out/main.js`.
This ensures, together with a properly set up `.vscodeignore` that the published
package stays small in size. Without that the package is easily over 2MB in
size, but properly configured it is under 400KB.

```ts : <<literate.*>>= ./src/extension.ts
import StateCore = require('markdown-it/lib/rules_core/state_core');
import Token = require('markdown-it/lib/token');
import { TextDecoder } from 'util';
import * as vscode from 'vscode';
import { posix } from 'path';

// `import` here fails so instead we require the highlight module
// this way. Not sure why import fails. It would be great to find
// out the reason.
const hljs = require('highlight.js');

import { grabberPlugin } from './grabber';

import MarkdownIt = require("markdown-it");
import Renderer = require('markdown-it/lib/renderer');

<<grabbed state type>>
<<fragment information type>>
<<fragment regular expressions>>

let oldFence : Renderer.RenderRule | undefined;

export function activate(context: vscode.ExtensionContext) {
	console.log('Ready to do some Literate Programming');
	const diagnostics = vscode.languages.createDiagnosticCollection('literate');
	//setupLanguageMapping();

	<<register literate.process>>

	if (vscode.window.activeTextEditor) {
		updateDiagnostics(vscode.window.activeTextEditor.document.uri, diagnostics, undefined);
	}
	context.subscriptions.push(vscode.window.onDidChangeActiveTextEditor(editor => {
		if (editor) {
			updateDiagnostics(editor.document.uri, diagnostics, undefined);
		}
	}));

	context.subscriptions.push(literateProcessDisposable);

	return {
		extendMarkdownIt(md: any) {
			md.use(grabberPlugin);
			oldFence = md.renderer.rules.fence;
			md.renderer.rules.fence = renderCodeFence;
			return md;
		}
	};
};

// eslint-disable-next-line @typescript-eslint/naming-convention
function codeFragmentCleanup(_: string, p1 : string, __: number, ___: string) {
	let cleaned = p1.replaceAll(/<.*?>/g, '');
	return `<span class="fragmentuse">${cleaned}</span>`;
}

<<renderCodeFence rule>>

function updateDiagnostics(uri: vscode.Uri, collection: vscode.DiagnosticCollection, diagnostic : vscode.Diagnostic | undefined): void {
	if (uri) {
		if (diagnostic) {
			const diags = Array.from(collection.get(uri) || []);
			diags.push(diagnostic);
			collection.set(uri, diags);
		}
	} else {
		collection.clear();
	}
}

/**
 * Create diagnostic for a given token with message.
 * @param token Token that carries the faulty code fragment
 * @param message Error message
 */
function createErrorDiagnostic(token: Token, message: string) : vscode.Diagnostic {
	let range = fragmentRange(token);
	let diagnostic: vscode.Diagnostic = {
		severity: vscode.DiagnosticSeverity.Error,
		message: message,
		range: range
	};

	return diagnostic;
}

/**
 * Give the location of the line in the Markup document that contains the
 * tag declaration.
 * @param token Token to extract code location from
 */
function locationOfFragment(token: Token): number {
	let linenumber = token.map ? (token.map[0]) : -1;
	return linenumber;
}

/**
 * Give the location of the last line in the Markup document that contains the
 * code fragment.
 * @param token Token to extract code location from
 */
function locationOfFragmentEnd(token: Token): number {
	let linenumber = token.map ? (token.map[1] ) : -1;
	return linenumber;
}


/**
 * Give range for the code fragment, including tag.
 * @param token Token to create range for
 */
function fragmentRange(token: Token): vscode.Range {
	let startTagName = token.info.indexOf("<<") + 2;
	let endTagName = token.info.indexOf(">>") - 1;
	let start = new vscode.Position(locationOfFragment(token), startTagName);
	let end = new vscode.Position(locationOfFragmentEnd(token), endTagName);
	let range: vscode.Range = new vscode.Range(start, end);
	return range;
}

/*
let languageMapping = new Map<string, string>();
function setupLanguageMapping() {
	languageMapping.set("csharp", "cs");
}

function extensionForLanguage(lang: string): string
{
	lang = lang.trim();
	if (lang.length <= 2) {
		return lang;
	}

	if (languageMapping.has(lang)) {
		let extension = languageMapping.get(lang);
		if (extension) {
			return extension;
		}
	}

	return 'xx';
}

*/

// this method is called when your extension is deactivated
export function deactivate() {}

```
